{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding new data to Open-Canopy\n",
    "\n",
    "In this notebook, we describe how to add new data to the Open-Canopy dataset. The process is straightforward once you understand the structure of the dataset. Quoting section A-3 of the supplementary material of the [paper](https://arxiv.org/pdf/2407.09392):\n",
    "\"\n",
    "The composition of the `canopy_height` folder is the following:\n",
    "- The file `geometries.geojson` stores a list of [...] geolocated geometries, giving access to the splits of the dataset. It can be loaded using the python package geopandas. Each geometry designates either a train, validation, test or buffer area. This information is stored in the column `split` [...]. Additionally, each geometry is associated to a year (corresponding to the year of the corresponding LiDAR acquisition), stored in the column `lidar_year`.\n",
    "*NB: In the original \"Open-Canopy\" dataset, the column \"lidar_year\" refers to the acquisition year of lidar data,\n",
    "but in a more general context, it designates a spatio-temporal zone with a unique crs, and should be filled with the name of the folder where to retrieve data for each geometry.*\n",
    "- The file `forest_mask.parquet` stores geolocated geometries of forestsâ€™ outlines. It can be loaded using the python package geopandas.[...]\n",
    "- Each folder 2021, 2022 and 2023 contains three files:\n",
    "    - `lidar.vrt` is a geolocalized virtual file that gives access to SPOT 6-7 images stored in the subfolder spot. It can be accessed through Qgis software 2 or python rasterio library 3 for instance. It has the same extent as the geometries of the associated year.\n",
    "    - Similarly `lidar.vrt` gives access to ALS-derived (LiDAR) canopy height maps stored in the subfolder lidar.\n",
    "    - Similarly `lidar_classification.vrt` gives access to classification rasters stored in the subfolder lidar_classification.\n",
    "\"\n",
    "\n",
    "**Hence, perform the following steps to add new data**\n",
    "- Create a new folder in the folder `canopy_height`.\n",
    "- In the newly created folder, add the following files:\n",
    "    - a GeoTIFF (`tif` extension) file (or a`vrt` with its associated files) named `spot.tif` for satellite imagery, at resolution 1.5m, with four bands RGB and NIR. See [preprocessing](../src/preprocessing/README.md) for pansharpening of SPOT imagery at 1.5m resolution. If you plan to use satellite or aerial imagery that comes from a different sensor, we recommend first applying histogram matching or a related technique with SPOT preprocessed data.\n",
    "    - [For evaluation/training] a `tif` (or `vrt`) named `lidar.tif` for ground truth canopy height, stored in decimeters, at 1.5m resolution\n",
    "    - [Optional for evaluation/training] a mask, stored in a `tif` (or `vrt`) named `lidar_classification.tif` specifying where to perform evaluation/training (cf. [evaluation config](../src/metrics/configs/compute_metrics_config.yaml)).\n",
    "\n",
    "Then update the `geometries.geojson` file to reflect the new training or evaluation set, as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import rasterio\n",
    "from shapely.geometry import box\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the existing geometries.geojson file before updating it\n",
    "path_to_dataset = Path('../datasets/canopy/canopy_height')\n",
    "new_data_name = \"my_new_data\" # Update with the name of the new folder where you have stored new data\n",
    "split = \"test\" # update with \"train/val/test/predict\"\n",
    "extension = \".tif\" # Replace with .vrt if using vrt\n",
    "\n",
    "path_to_new_data = os.path.join(path_to_dataset, new_data_name)\n",
    "path_to_geometries = os.path.join(path_to_dataset, 'geometries.geojson')\n",
    "print('Creating backup of the original geometries.geojson file')\n",
    "shutil.copy(path_to_geometries, os.path.join(path_to_dataset, \"initial_geometries.geojson\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a geometry corresponding to the new data\n",
    "with rasterio.open(os.path.join(path_to_new_data, \"spot\"+extension)) as src:\n",
    "    # Get the bounding box of the image\n",
    "    bounds = src.bounds\n",
    "# Create a polygon from the bounds\n",
    "new_geometry = box(bounds.left, bounds.bottom, bounds.right, bounds.top)\n",
    "\n",
    "# Update the \"geometries.geojson\" file\n",
    "gdf = gpd.read_file(path_to_geometries)\n",
    "# In the original \"Open-Canopy\" dataset, the column \"lidar_year\" refers to the acquisition year of lidar data,\n",
    "# but in a more general context, it just designates a folder with data as described above\n",
    "new_gdf = gpd.GeoDataFrame({'lidar_year': [new_data_name],'split': [split], 'geometry': [new_geometry]}, crs=gdf.crs)\n",
    "# Append the new GeoDataFrame to the original one\n",
    "gdf = pd.concat([gdf, new_gdf], ignore_index=True)\n",
    "# NB: other columns in gdf do not need to be filled\n",
    "# If you want to perform evaluation only on the new data, just keep the new geometry\n",
    "# gdf = new_gdf\n",
    "# Save the new geometries\n",
    "gdf.to_file(path_to_geometries, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result\n",
    "gdf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you do not have a classification_mask, you can create one corresponding to the pixels with height higher than a given threshold (e.g., 2m)\n",
    "threshold = 20 # heights are stored in decimeters\n",
    "with rasterio.open(os.path.join(path_to_new_data, \"lidar\"+extension)) as src:\n",
    "    lidar = src.read(1)\n",
    "    profile = src.profile.copy()\n",
    "# Threshold to get the mask, and use value 5 (corresponding to high vegetation)\n",
    "mask = (lidar >= threshold)*5\n",
    "# Save the mask\n",
    "profile.update(dtype=rasterio.uint8, count=1)\n",
    "with rasterio.open(os.path.join(path_to_new_data, \"lidar_classification.tif\"), 'w', **profile) as dst:\n",
    "    dst.write(mask.astype(rasterio.uint8), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that all needed files are present:\n",
    "assert os.path.exists(path_to_new_data), 'New data folder not found'\n",
    "assert os.path.exists(os.path.join(path_to_new_data, \"spot\"+extension)), 'spot file not found'\n",
    "assert os.path.exists(os.path.join(path_to_new_data, \"lidar\"+extension)), 'lidar file not found'\n",
    "assert os.path.exists(os.path.join(path_to_new_data, \"lidar_classification\"+extension)), 'lidar_classification file not found'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run training/evaluation\n",
    "For training (after updating the configs with e.g., your custom model)\n",
    "```bash\n",
    "python src/train.py model=my_custom_model\n",
    "```\n",
    "\n",
    "For evaluation only:\n",
    "```bash\n",
    "python src/eval.py <checkpoint_path> <train_config_path> task_name=test [extra_hydra_arg]\n",
    "```\n",
    "\n",
    "For prediction:\n",
    "```bash\n",
    "python src/eval.py <checkpoint_path> <train_config_path> task_name=predict [extra_hydra_arg]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
